{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **rnnを実装してみる**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **必要な関数・ライブラリ等の準備**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# データ加工・処理・分析モジュール\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def set_time(dataframe, col_name):\n",
    "    '''\n",
    "    to_datetimeを使うための前処理\n",
    "    '''\n",
    "    dataframe[col_name] = dataframe[col_name].map(lambda x : transform_time(x))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_time(x):\n",
    "    '''\n",
    "    set_time内で使う関数\n",
    "    to_datetimeで24時をサポートしないので00に変更する処理\n",
    "    '''\n",
    "    str_x = str(x)\n",
    "    res = ''\n",
    "    if str(x)[8:10] == '24':\n",
    "        res = str_x[0:4] + '-' + str_x[4:6] + '-' + str_x[6:8] + ' 00:'+str_x[10:12] \n",
    "    else:\n",
    "        res = str_x[0:4] + '-' + str_x[4:6] + '-' + str_x[6:8] + ' '+ str_x[8:10] +':'+str_x[10:12]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **データの準備**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>SOLA01</th>\n",
       "      <th>SOLA02</th>\n",
       "      <th>SOLA03</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 01:30:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  SOLA01  SOLA02  SOLA03\n",
       "0 2012-01-01 00:00:00       0     0.0     NaN\n",
       "1 2012-01-01 00:30:00       0     0.0     NaN\n",
       "2 2012-01-01 01:00:00       0     0.0     NaN\n",
       "3 2012-01-01 01:30:00       0     0.0     NaN\n",
       "4 2012-01-01 02:00:00       0     0.0     NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "# 処理済みデータを読み込む。無かったら作る\n",
    "try:\n",
    "    output_data = pd.read_csv('data/processed_data/out_put.tsv', delimiter = '\\t')\n",
    "    output_data['datetime'] = output_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "    \n",
    "except:\n",
    "    # train_kwhをエクセル等で開くとdatetimeが指数表示に直される可能性がある\n",
    "    # その場合うまくいかないので201201010120の形になってることを確認する必要あり\n",
    "    output_data = pd.read_csv('data/raw_data/train_kwh.tsv', delimiter = '\\t')\n",
    "\n",
    "    # datetimeの行をpd.Timestampのインスタンスに変更\n",
    "    output_data = set_time(output_data, 'datetime')\n",
    "    output_data['datetime'] = output_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "\n",
    "    # 30分ごとに合計を集計\n",
    "    output_data = output_data.set_index('datetime').groupby(pd.TimeGrouper(freq='1800s', closed='left')).sum()\n",
    "\n",
    "    output_data.to_csv('data/processed_data/out_put.tsv', sep='\\t') \n",
    "    \n",
    "output_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>pr</th>\n",
       "      <th>f_pr</th>\n",
       "      <th>max_ws</th>\n",
       "      <th>f_max_ws</th>\n",
       "      <th>ave_wv</th>\n",
       "      <th>f_ave_wv</th>\n",
       "      <th>ave_ws</th>\n",
       "      <th>f_ave_ws</th>\n",
       "      <th>max_tp</th>\n",
       "      <th>f_max_tp</th>\n",
       "      <th>min_tp</th>\n",
       "      <th>f_min_tp</th>\n",
       "      <th>sl</th>\n",
       "      <th>f_sl</th>\n",
       "      <th>sd</th>\n",
       "      <th>f_sd</th>\n",
       "      <th>dsd</th>\n",
       "      <th>f_dsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-15.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-01 00:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-34.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-35.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-43.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-01 01:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-36.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-42.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-40.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-48.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime   pr  f_pr     max_ws  f_max_ws     ave_wv  f_ave_wv  \\\n",
       "0 2012-01-01 00:00:00  0.0   0.0  22.333333       0.0  20.333333       0.0   \n",
       "1 2012-01-01 00:30:00  0.0   0.0  15.333333       0.0  25.000000       0.0   \n",
       "2 2012-01-01 01:00:00  0.0   0.0  20.000000       0.0  25.000000       0.0   \n",
       "3 2012-01-01 01:30:00  0.0   0.0  20.333333       0.0  21.666667       0.0   \n",
       "4 2012-01-01 02:00:00  0.0   0.0  25.333333       0.0  21.000000       0.0   \n",
       "\n",
       "      ave_ws  f_ave_ws     max_tp  f_max_tp     min_tp  f_min_tp   sl  f_sl  \\\n",
       "0  10.000000       0.0 -15.666667       0.0 -26.333333       0.0  0.0   2.0   \n",
       "1   9.333333       0.0 -34.666667       0.0 -40.000000       0.0  0.0   2.0   \n",
       "2  10.666667       0.0 -35.333333       0.0 -43.666667       0.0  0.0   2.0   \n",
       "3  11.333333       0.0 -36.666667       0.0 -42.333333       0.0  0.0   2.0   \n",
       "4  13.333333       0.0 -40.666667       0.0 -48.000000       0.0  0.0   2.0   \n",
       "\n",
       "    sd  f_sd  dsd  f_dsd  \n",
       "0  0.0   0.0  0.0    0.0  \n",
       "1  0.0   0.0  0.0    0.0  \n",
       "2  0.0   0.0  0.0    0.0  \n",
       "3  0.0   0.0  0.0    0.0  \n",
       "4  0.0   0.0  0.0    0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データの読み込み\n",
    "# 処理済みデータを読み込む。無かったら作る\n",
    "try:\n",
    "    amd_data = pd.read_csv('data/processed_data/amd_data.tsv', delimiter='\\t')\n",
    "    amd_data['datetime'] = amd_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "    \n",
    "except:\n",
    "    # 河口湖アメダスのデータを使って予測する, amd_49251\n",
    "    # 各amdidはamd_masterに記載されている\n",
    "    amd_data = pd.read_csv('data/raw_data/amd_49251.tsv', delimiter = '\\t')\n",
    "\n",
    "    amd_data = set_time(amd_data, 'datetime')\n",
    "    amd_data['datetime'] = amd_data['datetime'].map(lambda x : pd.to_datetime(x))\n",
    "\n",
    "    # 30分ごとに平均を集計\n",
    "    amd_data = amd_data.set_index('datetime').groupby(pd.TimeGrouper(freq='1800s', closed='left')).mean()\n",
    "\n",
    "    amd_data.to_csv('data/processed_data/amd_data.tsv', sep='\\t')\n",
    "\n",
    "amd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデル構築のためにデータを分割する\n",
    "\n",
    "# 日射量の欠損値を一つ前の値で置換/output_dataに関してはSOLA01はnullなし\n",
    "amd_data['sl'] = amd_data['sl'].fillna(method='bfill')\n",
    "\n",
    "# 学習に必要なデータ\n",
    "# 2012/01/01 00:00 ~ 2015/12/30 20:00のamdデータを用いて\n",
    "# 2012/01/03 03:30 ~ 2015/12/31 23:30のデータを予測する\n",
    "train_x_startID = amd_data[amd_data['datetime'] == pd.to_datetime('2012-01-01 00:00')].index[0]\n",
    "train_x_endID = amd_data[amd_data['datetime'] == pd.to_datetime('2015-12-30 20:00')].index[0]\n",
    "train_y_startID = amd_data[amd_data['datetime'] == pd.to_datetime('2012-01-03 03:30')].index[0]\n",
    "train_y_endID = amd_data[amd_data['datetime'] == pd.to_datetime('2015-12-31 23:30')].index[0]\n",
    "\n",
    "train_amd_data = list(amd_data['sl'][train_x_startID:(train_x_endID+1)])\n",
    "train_output_data = list(output_data['SOLA01'][train_y_startID:(train_y_endID+1)])\n",
    "\n",
    "#時系列データのリストにする\n",
    "input_list = []\n",
    "for i in range(0, len(train_amd_data) - 48):\n",
    "    input_list.append(train_amd_data[i : i + 49])\n",
    "\n",
    "# 予測に必要なデータ\n",
    "# 2015/12/30 20:30 ~ 2017/3/30 20:00のamdデータを用いて\n",
    "# 2016/01/01 00:00 ~ 2017/3/31 23:30のoutputデータを予測する\n",
    "test_startID = amd_data[amd_data['datetime'] == pd.to_datetime('2015-12-30 20:30')].index[0]\n",
    "test_endID = amd_data[amd_data['datetime'] == pd.to_datetime('2017-3-30 20:00')].index[0]\n",
    "\n",
    "test_amd_data = list(amd_data['sl'][test_startID:(test_endID+1)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **モデルの構築**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前日の20時までの河口個のアメダスの日射量データを用いて翌日の00:00~23:30を予測する\n",
    "(例)\n",
    "\n",
    "8/17の00:00 ~ 23:30を予測するとき\n",
    "\n",
    "8/17の23:30を8/15 20:00 ~ 8/16 20:00\n",
    "\n",
    "8/17の23:00を8/15 19:30 ~ 8/16 19:30\n",
    "\n",
    "....\n",
    "\n",
    "8/17の00:00を8/14 20:30 ~ 8/15 20:30で予測する\n",
    "\n",
    "参考サイト：http://www.madopro.net/entry/char_level_lm_with_simple_rnn\n",
    "\n",
    "          https://book.mynavi.jp/manatee/detail/id=76290\n",
    "          \n",
    "          https://book.mynavi.jp/manatee/detail/id=76856\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class simpleRNN:\n",
    "    def __init__(self):\n",
    "        self.input_layer_size = 1 #入力層の数、一つ一つのデータはslの値ひとつだけなので1\n",
    "        self.hidden_layer_size = 47 # 隠れ層の数、とりあえず系列データの長さ分だけ用意しておく\n",
    "        self.output_layer_size = 1 #出力層の数、求める値は時間あたりの発電量の値1つなので1\n",
    "        self.batch_size = 100 #バッチサイズ、適当\n",
    "        self.chunk_size = 47 # 一回の系列データの長さ\n",
    "        self.learning_rate = 0.001 # 学習率適当\n",
    "        self.epochs = 1000 #エポック数\n",
    "        \n",
    "    def inference(self, input_data, initial_state):\n",
    "        \n",
    "        # 重みとバイアスの初期化\n",
    "        hidden_w = tf.Variable(tf.truncated_normal([self.input_layer_size, self.hidden_layer_size], stddev=0.01))\n",
    "        hidden_b = tf.Variable(tf.ones([self.hidden_layer_size]))\n",
    "        output_w = tf.Variable(tf.truncated_normal([self.hidden_layer_size, self.output_layer_size], stddev=0.01))\n",
    "        output_b = tf.Variable(tf.ones([self.output_layer_size]))\n",
    "        \n",
    "            \n",
    "        # BasicRNNCellを定義\n",
    "        cell = tf.contrib.rnn.BasicRNNCell(self.hidden_layer_size)\n",
    "        outputs, states = tf.contrib.rnn.static_rnn(cell, input_data, initial_state=initial_state)\n",
    "\n",
    "        output = tf.matmul(outputs[-1], output_w) + output_b\n",
    "        return output\n",
    "        \n",
    "    def loss(self, output, actual_value):\n",
    "        cost = tf.reduce_mean(tf.abs(output - actual_value))\n",
    "        return cost\n",
    "    \n",
    "    def training(self, cost):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=self.learning_rate, beta=0.9, beta2=0.999).minimize(cost)\n",
    "        return optimizer\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        # 変数の用意\n",
    "        input_data = tf.placeholder('float', [None, self.chunk_size, self.input_layer_size])\n",
    "        actual_value = tf.placeholder('float', [None, self.output_layer_size])\n",
    "        initial_state = tf.placeholder('float', [None, self.hidden_layer_size])\n",
    "        \n",
    "        prediction = self.inference(input_data, initial_state)\n",
    "        cost = self.loss(prediction, actual_value)\n",
    "        optimizer = self.training(cost)\n",
    "    \n",
    "        # TensorBoardで可視化する\n",
    "        tf.summary.scalar(\"AME\", cost)\n",
    "        summary = tf.summary.merge_all()\n",
    "        \n",
    "        # 学習データの用意\n",
    "        trX = X\n",
    "        trY = Y\n",
    "        training_num = x.shape[0]\n",
    "                \n",
    "        # ログを保存するためのディレクトリ\n",
    "        timestamp = time.time()\n",
    "        dirname = datetime.datetime.fromtimestamp(timestamp).strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "        # ここから学習\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            summary_wtiter = tf.summary.FileWriter(\"./log/\" + dirname, sess.graph)\n",
    "            \n",
    "            for epoch in range(self.epochs):\n",
    "                step = 0\n",
    "                epoch_loss = 0\n",
    "                \n",
    "                # 訓練データをバッチサイズごとに分けて学習する\n",
    "                while (step + 1) * self.batch_size < training_num:\n",
    "                    start_idx = step * batch_size\n",
    "                    end_idx = (step + 1) * self.batch_size\n",
    "                    batch_xs = trX[start_idx:end_idx, :, :]\n",
    "                    batch_ys = trY[start_idx:end_idx, :, :]\n",
    "                    \n",
    "                    _, c = sess.run([optimizer, cost], feed_dict={input_data: batch_xs, actual_labels: batch_ys, initial_state: np.zeros([self.batch_size, self.hidden_layer_size])})\n",
    "                    epoch_loss += c\n",
    "                    step += 1\n",
    "                  \n",
    "                # コンソールに損失関数の値や精度を出力しておく\n",
    "                print(\"Epoch\", epoch, \"completed ouf of\", self.epochs, \"-- loss:\", epoch_loss)\n",
    "                \n",
    "                # Epochが終わるごとにTensorBoard用に値を保存\n",
    "                summary_str = sess.run(summary, feed_dict={input_data: trX, actual_labels: trY, initial_state: np.zeros([trX.shape[0], self.hidden_layer_size])})\n",
    "                summary_writer.add_summary(summary_str, epoch)\n",
    "                summary_writer.flush()\n",
    "                \n",
    "        # 学習したモデルも保存しておく\n",
    "        saver = tf.train.Saver()\n",
    "        saver.save(sess, \"./data/wiki2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_01 = simpleRNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "inputs must be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-9e684ebddc4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_01\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-7e597839f5dc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0minitial_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-129-7e597839f5dc>\u001b[0m in \u001b[0;36minference\u001b[0;34m(self, input_data, initial_state)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# BasicRNNCellを定義\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasicRNNCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_w\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutput_b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mstatic_rnn\u001b[0;34m(cell, inputs, initial_state, dtype, sequence_length, scope)\u001b[0m\n\u001b[1;32m   1142\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cell must be an instance of RNNCell\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs must be a sequence\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inputs must not be empty\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: inputs must be a sequence"
     ]
    }
   ],
   "source": [
    "model_01.train(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(input_list).reshape(len(input_list), 49, 1)\n",
    "Y = np.array(train_output_data).reshape(len(input_list), 1 )\n",
    "\n",
    "N_train = int(len(input_list) * 0.9)\n",
    "N_val = len(input_list) - N_train\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=N_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(x, n_batch, maxlen=None, n_hidden=None, n_out=None):\n",
    "    def weight_variable(shape):\n",
    "        initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "        return tf.Variable(initial)\n",
    " \n",
    "    def bias_variable(shape):\n",
    "        initial = tf.zeros(shape, dtype=tf.float32)\n",
    "        return tf.Variable(initial)\n",
    " \n",
    "    cell = tf.contrib.rnn.BasicRNNCell(n_hidden)\n",
    "    initial_state = cell.zero_state(n_batch, tf.float32)\n",
    " \n",
    "    state = initial_state\n",
    "    outputs = [] # 過去の隠れ層の出力を保存\n",
    "    print(\"here\")\n",
    "    with tf.variable_scope('RNN'):\n",
    "        for t in range(maxlen):\n",
    "            if t > 0:\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "            (cell_output, state) = cell(x[:, t, :], state)\n",
    "            outputs.append(cell_output)\n",
    " \n",
    "    output = outputs[-1]\n",
    " \n",
    "    V = weight_variable([n_hidden, n_out])\n",
    "    c = bias_variable([n_out])\n",
    "    y = tf.matmul(output, V) + c # 線形活性\n",
    " \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y, t):\n",
    "    mae = tf.reduce_mean(tf.abs(y - t))\n",
    "    return mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def training(loss):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.9, beta2=0.999)\n",
    " \n",
    "    train_step = optimizer.minimize(loss)\n",
    "    return train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "maxlen = 49\n",
    "n_in = 1\n",
    "n_hidden = 20\n",
    "n_out = 1\n",
    " \n",
    "x = tf.placeholder(tf.float32, shape=[None, maxlen, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "n_batch = tf.placeholder(tf.int32, shape=[])\n",
    " \n",
    "y = inference(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out=n_out)\n",
    "loss = loss(y, t)\n",
    "train_step = training(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [22,1] vs. shape[1] = [100,20]\n\t [[Node: RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](RNN/strided_slice, BasicRNNCellZeroState/zeros, RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat/axis)]]\n\nCaused by op 'RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat', defined at:\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-128-b88a64061f01>\", line 12, in <module>\n    y = inference(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out=n_out)\n  File \"<ipython-input-109-c4b6fa79b755>\", line 19, in inference\n    (cell_output, state) = cell(x[:, t, :], state)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 180, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 450, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 258, in call\n    output = self._activation(_linear([inputs, state], self._num_units, True))\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1043, in _linear\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1066, in concat\n    name=name)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 493, in _concat_v2\n    name=name)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [22,1] vs. shape[1] = [100,20]\n\t [[Node: RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](RNN/strided_slice, BasicRNNCellZeroState/zeros, RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat/axis)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [22,1] vs. shape[1] = [100,20]\n\t [[Node: RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](RNN/strided_slice, BasicRNNCellZeroState/zeros, RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat/axis)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-5fcef967d1dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mX_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mY_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mn_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         })\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [22,1] vs. shape[1] = [100,20]\n\t [[Node: RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](RNN/strided_slice, BasicRNNCellZeroState/zeros, RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat/axis)]]\n\nCaused by op 'RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat', defined at:\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-128-b88a64061f01>\", line 12, in <module>\n    y = inference(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out=n_out)\n  File \"<ipython-input-109-c4b6fa79b755>\", line 19, in inference\n    (cell_output, state) = cell(x[:, t, :], state)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 180, in __call__\n    return super(RNNCell, self).__call__(inputs, state)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 450, in __call__\n    outputs = self.call(inputs, *args, **kwargs)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 258, in call\n    output = self._activation(_linear([inputs, state], self._num_units, True))\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 1043, in _linear\n    res = math_ops.matmul(array_ops.concat(args, 1), weights)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1066, in concat\n    name=name)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 493, in _concat_v2\n    name=name)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2630, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/Users/kyojin_syo/anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1204, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [22,1] vs. shape[1] = [100,20]\n\t [[Node: RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](RNN/strided_slice, BasicRNNCellZeroState/zeros, RNN/RNN/basic_rnn_cell/basic_rnn_cell/concat/axis)]]\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 100\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "n_batches = N_train\n",
    "\n",
    "loss_log = []\n",
    " \n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ = X_train, Y_train\n",
    " \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    " \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end],\n",
    "            n_batch: batch_size\n",
    "        })\n",
    " \n",
    "    # 検証データを用いた評価\n",
    "    val_loss = loss.eval(session=sess, feed_dict={\n",
    "        x: X_val,\n",
    "        t: Y_val,\n",
    "        n_batch: N_val\n",
    "    })\n",
    "    \n",
    "    loss_log.append(val_loss)\n",
    "    print('epoch:', epoch,\n",
    "          ' validation loss:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sin(x, T=100):\n",
    "    return np.sin(2.0 * np.pi * x / T)\n",
    " \n",
    "def toy_problem(T=100, ampl=0.05):\n",
    "    x = np.arange(0, 2 * T + 1)\n",
    "    noise = ampl * np.random.uniform(low=-1.0, high=1.0, size=len(x))\n",
    "    return sin(x) + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "T = 100\n",
    "f = toy_problem(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "length_of_sequences = 2 * T # 全時系列の長さ\n",
    "maxlen = 25 # 1 つの時系列データの長さ\n",
    " \n",
    "data = []\n",
    "target = []\n",
    " \n",
    "for i in range(0, length_of_sequences - maxlen + 1):\n",
    "    data.append(f[i: i + maxlen])\n",
    "    target.append(f[i + maxlen])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.array(data).reshape(len(data), maxlen, 1)\n",
    "\n",
    "\n",
    "Y = np.array(target).reshape(len(data), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(176, 25, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "N_train = int(len(data) * 0.9)\n",
    "N_validation = len(data) - N_train\n",
    " \n",
    "X_train, X_validation, Y_train, Y_validation = \\\n",
    "    train_test_split(X, Y, test_size=N_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(y, t):\n",
    "    mse = tf.reduce_mean(tf.square(y - t))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "n_in = len(X[0][0]) # 1\n",
    "n_hidden = 20\n",
    "n_out = len(Y[0]) # 1\n",
    " \n",
    "x = tf.placeholder(tf.float32, shape=[None, maxlen, n_in])\n",
    "t = tf.placeholder(tf.float32, shape=[None, n_out])\n",
    "n_batch = tf.placeholder(tf.int32, shape=[])\n",
    " \n",
    "y = inference(x, n_batch, maxlen=maxlen, n_hidden=n_hidden, n_out=n_out)\n",
    "loss = loss(y, t)\n",
    "train_step = training(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0  validation loss: 0.487704\n",
      "epoch: 1  validation loss: 0.366794\n",
      "epoch: 2  validation loss: 0.20489\n",
      "epoch: 3  validation loss: 0.106216\n",
      "epoch: 4  validation loss: 0.060803\n",
      "epoch: 5  validation loss: 0.0331577\n",
      "epoch: 6  validation loss: 0.021167\n",
      "epoch: 7  validation loss: 0.0161661\n",
      "epoch: 8  validation loss: 0.0109976\n",
      "epoch: 9  validation loss: 0.00864371\n",
      "epoch: 10  validation loss: 0.0065437\n",
      "epoch: 11  validation loss: 0.00605534\n",
      "epoch: 12  validation loss: 0.00514589\n",
      "epoch: 13  validation loss: 0.00511408\n",
      "epoch: 14  validation loss: 0.00493279\n",
      "epoch: 15  validation loss: 0.00484831\n",
      "epoch: 16  validation loss: 0.00474341\n",
      "epoch: 17  validation loss: 0.00459985\n",
      "epoch: 18  validation loss: 0.00425988\n",
      "epoch: 19  validation loss: 0.00411223\n",
      "epoch: 20  validation loss: 0.00425674\n",
      "epoch: 21  validation loss: 0.00419291\n",
      "epoch: 22  validation loss: 0.00420972\n",
      "epoch: 23  validation loss: 0.004283\n",
      "epoch: 24  validation loss: 0.0042607\n",
      "epoch: 25  validation loss: 0.00428406\n",
      "epoch: 26  validation loss: 0.00429898\n",
      "epoch: 27  validation loss: 0.00427101\n",
      "epoch: 28  validation loss: 0.00423216\n",
      "epoch: 29  validation loss: 0.00418192\n",
      "epoch: 30  validation loss: 0.00412274\n",
      "epoch: 31  validation loss: 0.00402106\n",
      "epoch: 32  validation loss: 0.003996\n",
      "epoch: 33  validation loss: 0.00393155\n",
      "epoch: 34  validation loss: 0.00392723\n",
      "epoch: 35  validation loss: 0.0039066\n",
      "epoch: 36  validation loss: 0.00388922\n",
      "epoch: 37  validation loss: 0.00390289\n",
      "epoch: 38  validation loss: 0.00386663\n",
      "epoch: 39  validation loss: 0.00386459\n",
      "epoch: 40  validation loss: 0.00389763\n",
      "epoch: 41  validation loss: 0.00389749\n",
      "epoch: 42  validation loss: 0.00390955\n",
      "epoch: 43  validation loss: 0.00405594\n",
      "epoch: 44  validation loss: 0.00424639\n",
      "epoch: 45  validation loss: 0.00387806\n",
      "epoch: 46  validation loss: 0.00385481\n",
      "epoch: 47  validation loss: 0.00399018\n",
      "epoch: 48  validation loss: 0.00361116\n",
      "epoch: 49  validation loss: 0.0036326\n",
      "epoch: 50  validation loss: 0.00389987\n",
      "epoch: 51  validation loss: 0.00361282\n",
      "epoch: 52  validation loss: 0.00353907\n",
      "epoch: 53  validation loss: 0.00375986\n",
      "epoch: 54  validation loss: 0.00361935\n",
      "epoch: 55  validation loss: 0.00344741\n",
      "epoch: 56  validation loss: 0.00356357\n",
      "epoch: 57  validation loss: 0.00370734\n",
      "epoch: 58  validation loss: 0.00346999\n",
      "epoch: 59  validation loss: 0.00328766\n",
      "epoch: 60  validation loss: 0.00368631\n",
      "epoch: 61  validation loss: 0.00357234\n",
      "epoch: 62  validation loss: 0.00337154\n",
      "epoch: 63  validation loss: 0.00330816\n",
      "epoch: 64  validation loss: 0.00369305\n",
      "epoch: 65  validation loss: 0.00347742\n",
      "epoch: 66  validation loss: 0.00314568\n",
      "epoch: 67  validation loss: 0.00347049\n",
      "epoch: 68  validation loss: 0.00366408\n",
      "epoch: 69  validation loss: 0.00343116\n",
      "epoch: 70  validation loss: 0.00304866\n",
      "epoch: 71  validation loss: 0.00360304\n",
      "epoch: 72  validation loss: 0.00349296\n",
      "epoch: 73  validation loss: 0.00342643\n",
      "epoch: 74  validation loss: 0.00341537\n",
      "epoch: 75  validation loss: 0.00319969\n",
      "epoch: 76  validation loss: 0.00344948\n",
      "epoch: 77  validation loss: 0.00351445\n",
      "epoch: 78  validation loss: 0.00345425\n",
      "epoch: 79  validation loss: 0.00306288\n",
      "epoch: 80  validation loss: 0.00357046\n",
      "epoch: 81  validation loss: 0.00352264\n",
      "epoch: 82  validation loss: 0.00346225\n",
      "epoch: 83  validation loss: 0.00317636\n",
      "epoch: 84  validation loss: 0.00343529\n",
      "epoch: 85  validation loss: 0.00354094\n",
      "epoch: 86  validation loss: 0.00338782\n",
      "epoch: 87  validation loss: 0.00305527\n",
      "epoch: 88  validation loss: 0.00362596\n",
      "epoch: 89  validation loss: 0.00357278\n",
      "epoch: 90  validation loss: 0.00343038\n",
      "epoch: 91  validation loss: 0.0035577\n",
      "epoch: 92  validation loss: 0.00310055\n",
      "epoch: 93  validation loss: 0.00332681\n",
      "epoch: 94  validation loss: 0.00377901\n",
      "epoch: 95  validation loss: 0.00323497\n",
      "epoch: 96  validation loss: 0.00297149\n",
      "epoch: 97  validation loss: 0.00373604\n",
      "epoch: 98  validation loss: 0.00349372\n",
      "epoch: 99  validation loss: 0.00337608\n",
      "epoch: 100  validation loss: 0.00352212\n",
      "epoch: 101  validation loss: 0.00323061\n",
      "epoch: 102  validation loss: 0.0034136\n",
      "epoch: 103  validation loss: 0.00360088\n",
      "epoch: 104  validation loss: 0.0031952\n",
      "epoch: 105  validation loss: 0.00310046\n",
      "epoch: 106  validation loss: 0.00360136\n",
      "epoch: 107  validation loss: 0.00361181\n",
      "epoch: 108  validation loss: 0.00347742\n",
      "epoch: 109  validation loss: 0.00330715\n",
      "epoch: 110  validation loss: 0.00329923\n",
      "epoch: 111  validation loss: 0.00355094\n",
      "epoch: 112  validation loss: 0.00308433\n",
      "epoch: 113  validation loss: 0.00321569\n",
      "epoch: 114  validation loss: 0.00367038\n",
      "epoch: 115  validation loss: 0.00329454\n",
      "epoch: 116  validation loss: 0.00326009\n",
      "epoch: 117  validation loss: 0.00349498\n",
      "epoch: 118  validation loss: 0.00326675\n",
      "epoch: 119  validation loss: 0.00337078\n",
      "epoch: 120  validation loss: 0.00341362\n",
      "epoch: 121  validation loss: 0.0032591\n",
      "epoch: 122  validation loss: 0.00336855\n",
      "epoch: 123  validation loss: 0.00340894\n",
      "epoch: 124  validation loss: 0.00331587\n",
      "epoch: 125  validation loss: 0.00334321\n",
      "epoch: 126  validation loss: 0.0033037\n",
      "epoch: 127  validation loss: 0.00333439\n",
      "epoch: 128  validation loss: 0.00324093\n",
      "epoch: 129  validation loss: 0.0032573\n",
      "epoch: 130  validation loss: 0.00341001\n",
      "epoch: 131  validation loss: 0.00294127\n",
      "epoch: 132  validation loss: 0.00330829\n",
      "epoch: 133  validation loss: 0.00347479\n",
      "epoch: 134  validation loss: 0.00281142\n",
      "epoch: 135  validation loss: 0.00321582\n",
      "epoch: 136  validation loss: 0.00345786\n",
      "epoch: 137  validation loss: 0.00233046\n",
      "epoch: 138  validation loss: 0.00285782\n",
      "epoch: 139  validation loss: 0.00305193\n",
      "epoch: 140  validation loss: 0.00383371\n",
      "epoch: 141  validation loss: 0.00235992\n",
      "epoch: 142  validation loss: 0.00292314\n",
      "epoch: 143  validation loss: 0.00295401\n",
      "epoch: 144  validation loss: 0.0036654\n",
      "epoch: 145  validation loss: 0.00273731\n",
      "epoch: 146  validation loss: 0.00337796\n",
      "epoch: 147  validation loss: 0.00311142\n",
      "epoch: 148  validation loss: 0.00360765\n",
      "epoch: 149  validation loss: 0.00319715\n",
      "epoch: 150  validation loss: 0.00349984\n",
      "epoch: 151  validation loss: 0.00329829\n",
      "epoch: 152  validation loss: 0.0033548\n",
      "epoch: 153  validation loss: 0.00327232\n",
      "epoch: 154  validation loss: 0.00323676\n",
      "epoch: 155  validation loss: 0.00321316\n",
      "epoch: 156  validation loss: 0.003206\n",
      "epoch: 157  validation loss: 0.0031767\n",
      "epoch: 158  validation loss: 0.00315765\n",
      "epoch: 159  validation loss: 0.00315076\n",
      "epoch: 160  validation loss: 0.00316377\n",
      "epoch: 161  validation loss: 0.00311724\n",
      "epoch: 162  validation loss: 0.00312018\n",
      "epoch: 163  validation loss: 0.00316931\n",
      "epoch: 164  validation loss: 0.00307163\n",
      "epoch: 165  validation loss: 0.00309469\n",
      "epoch: 166  validation loss: 0.00318244\n",
      "epoch: 167  validation loss: 0.00303731\n",
      "epoch: 168  validation loss: 0.00307502\n",
      "epoch: 169  validation loss: 0.00318363\n",
      "epoch: 170  validation loss: 0.00303824\n",
      "epoch: 171  validation loss: 0.00306228\n",
      "epoch: 172  validation loss: 0.00316167\n",
      "epoch: 173  validation loss: 0.0030479\n",
      "epoch: 174  validation loss: 0.00305568\n",
      "epoch: 175  validation loss: 0.00312942\n",
      "epoch: 176  validation loss: 0.0030501\n",
      "epoch: 177  validation loss: 0.00305598\n",
      "epoch: 178  validation loss: 0.00310079\n",
      "epoch: 179  validation loss: 0.00304964\n",
      "epoch: 180  validation loss: 0.00306207\n",
      "epoch: 181  validation loss: 0.0030793\n",
      "epoch: 182  validation loss: 0.00305266\n",
      "epoch: 183  validation loss: 0.00307169\n",
      "epoch: 184  validation loss: 0.00306155\n",
      "epoch: 185  validation loss: 0.00306244\n",
      "epoch: 186  validation loss: 0.00307932\n",
      "epoch: 187  validation loss: 0.00304379\n",
      "epoch: 188  validation loss: 0.00307651\n",
      "epoch: 189  validation loss: 0.00307832\n",
      "epoch: 190  validation loss: 0.00303281\n",
      "epoch: 191  validation loss: 0.00308026\n",
      "epoch: 192  validation loss: 0.00307565\n",
      "epoch: 193  validation loss: 0.00305397\n",
      "epoch: 194  validation loss: 0.00306231\n",
      "epoch: 195  validation loss: 0.0030881\n",
      "epoch: 196  validation loss: 0.00308314\n",
      "epoch: 197  validation loss: 0.0030345\n",
      "epoch: 198  validation loss: 0.00309559\n",
      "epoch: 199  validation loss: 0.00308314\n",
      "epoch: 200  validation loss: 0.00305697\n",
      "epoch: 201  validation loss: 0.00305945\n",
      "epoch: 202  validation loss: 0.00310996\n",
      "epoch: 203  validation loss: 0.00308719\n",
      "epoch: 204  validation loss: 0.00302577\n",
      "epoch: 205  validation loss: 0.00308525\n",
      "epoch: 206  validation loss: 0.00310536\n",
      "epoch: 207  validation loss: 0.00309348\n",
      "epoch: 208  validation loss: 0.00302359\n",
      "epoch: 209  validation loss: 0.00310923\n",
      "epoch: 210  validation loss: 0.00309416\n",
      "epoch: 211  validation loss: 0.00309614\n",
      "epoch: 212  validation loss: 0.00302663\n",
      "epoch: 213  validation loss: 0.00311979\n",
      "epoch: 214  validation loss: 0.00309147\n",
      "epoch: 215  validation loss: 0.00310067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 216  validation loss: 0.00302066\n",
      "epoch: 217  validation loss: 0.00310349\n",
      "epoch: 218  validation loss: 0.00311542\n",
      "epoch: 219  validation loss: 0.00309413\n",
      "epoch: 220  validation loss: 0.00300539\n",
      "epoch: 221  validation loss: 0.00305731\n",
      "epoch: 222  validation loss: 0.00316559\n",
      "epoch: 223  validation loss: 0.00305057\n",
      "epoch: 224  validation loss: 0.00300156\n",
      "epoch: 225  validation loss: 0.0030297\n",
      "epoch: 226  validation loss: 0.00317304\n",
      "epoch: 227  validation loss: 0.00304867\n",
      "epoch: 228  validation loss: 0.00307119\n",
      "epoch: 229  validation loss: 0.00302101\n",
      "epoch: 230  validation loss: 0.0030826\n",
      "epoch: 231  validation loss: 0.00315227\n",
      "epoch: 232  validation loss: 0.00306147\n",
      "epoch: 233  validation loss: 0.00300418\n",
      "epoch: 234  validation loss: 0.00303031\n",
      "epoch: 235  validation loss: 0.00315397\n",
      "epoch: 236  validation loss: 0.00309249\n",
      "epoch: 237  validation loss: 0.00308049\n",
      "epoch: 238  validation loss: 0.00300826\n",
      "epoch: 239  validation loss: 0.00303121\n",
      "epoch: 240  validation loss: 0.00317348\n",
      "epoch: 241  validation loss: 0.00307195\n",
      "epoch: 242  validation loss: 0.00307199\n",
      "epoch: 243  validation loss: 0.00301713\n",
      "epoch: 244  validation loss: 0.0030349\n",
      "epoch: 245  validation loss: 0.00316998\n",
      "epoch: 246  validation loss: 0.00308304\n",
      "epoch: 247  validation loss: 0.00307254\n",
      "epoch: 248  validation loss: 0.00301949\n",
      "epoch: 249  validation loss: 0.00303529\n",
      "epoch: 250  validation loss: 0.00315341\n",
      "epoch: 251  validation loss: 0.00312095\n",
      "epoch: 252  validation loss: 0.00307274\n",
      "epoch: 253  validation loss: 0.00301991\n",
      "epoch: 254  validation loss: 0.0030458\n",
      "epoch: 255  validation loss: 0.00311846\n",
      "epoch: 256  validation loss: 0.00317129\n",
      "epoch: 257  validation loss: 0.00306158\n",
      "epoch: 258  validation loss: 0.00303898\n",
      "epoch: 259  validation loss: 0.00304423\n",
      "epoch: 260  validation loss: 0.00306085\n",
      "epoch: 261  validation loss: 0.00316195\n",
      "epoch: 262  validation loss: 0.00312512\n",
      "epoch: 263  validation loss: 0.00307444\n",
      "epoch: 264  validation loss: 0.00302924\n",
      "epoch: 265  validation loss: 0.00306421\n",
      "epoch: 266  validation loss: 0.00311019\n",
      "epoch: 267  validation loss: 0.00317953\n",
      "epoch: 268  validation loss: 0.00310955\n",
      "epoch: 269  validation loss: 0.00307393\n",
      "epoch: 270  validation loss: 0.00303731\n",
      "epoch: 271  validation loss: 0.00307701\n",
      "epoch: 272  validation loss: 0.0031277\n",
      "epoch: 273  validation loss: 0.00318204\n",
      "epoch: 274  validation loss: 0.00312619\n",
      "epoch: 275  validation loss: 0.00308012\n",
      "epoch: 276  validation loss: 0.00304529\n",
      "epoch: 277  validation loss: 0.00308656\n",
      "epoch: 278  validation loss: 0.00312614\n",
      "epoch: 279  validation loss: 0.00317557\n",
      "epoch: 280  validation loss: 0.0031633\n",
      "epoch: 281  validation loss: 0.00310171\n",
      "epoch: 282  validation loss: 0.00306547\n",
      "epoch: 283  validation loss: 0.00307629\n",
      "epoch: 284  validation loss: 0.00311563\n",
      "epoch: 285  validation loss: 0.00316528\n",
      "epoch: 286  validation loss: 0.00318729\n",
      "epoch: 287  validation loss: 0.00314805\n",
      "epoch: 288  validation loss: 0.00310831\n",
      "epoch: 289  validation loss: 0.00307708\n",
      "epoch: 290  validation loss: 0.00309477\n",
      "epoch: 291  validation loss: 0.00313105\n",
      "epoch: 292  validation loss: 0.00317075\n",
      "epoch: 293  validation loss: 0.00318443\n",
      "epoch: 294  validation loss: 0.00315891\n",
      "epoch: 295  validation loss: 0.00312758\n",
      "epoch: 296  validation loss: 0.00309906\n",
      "epoch: 297  validation loss: 0.0030973\n",
      "epoch: 298  validation loss: 0.00312204\n",
      "epoch: 299  validation loss: 0.00315183\n",
      "epoch: 300  validation loss: 0.0031723\n",
      "epoch: 301  validation loss: 0.00316965\n",
      "epoch: 302  validation loss: 0.00315079\n",
      "epoch: 303  validation loss: 0.00312932\n",
      "epoch: 304  validation loss: 0.00311137\n",
      "epoch: 305  validation loss: 0.00310908\n",
      "epoch: 306  validation loss: 0.00312083\n",
      "epoch: 307  validation loss: 0.00313726\n",
      "epoch: 308  validation loss: 0.00314949\n",
      "epoch: 309  validation loss: 0.00315147\n",
      "epoch: 310  validation loss: 0.00314422\n",
      "epoch: 311  validation loss: 0.00313246\n",
      "epoch: 312  validation loss: 0.00312073\n",
      "epoch: 313  validation loss: 0.00311314\n",
      "epoch: 314  validation loss: 0.00311167\n",
      "epoch: 315  validation loss: 0.0031148\n",
      "epoch: 316  validation loss: 0.00311941\n",
      "epoch: 317  validation loss: 0.00312256\n",
      "epoch: 318  validation loss: 0.0031226\n",
      "epoch: 319  validation loss: 0.00311961\n",
      "epoch: 320  validation loss: 0.00311468\n",
      "epoch: 321  validation loss: 0.00310927\n",
      "epoch: 322  validation loss: 0.00310458\n",
      "epoch: 323  validation loss: 0.00310125\n",
      "epoch: 324  validation loss: 0.00309926\n",
      "epoch: 325  validation loss: 0.00309813\n",
      "epoch: 326  validation loss: 0.00309723\n",
      "epoch: 327  validation loss: 0.00309607\n",
      "epoch: 328  validation loss: 0.00309438\n",
      "epoch: 329  validation loss: 0.00309215\n",
      "epoch: 330  validation loss: 0.00308955\n",
      "epoch: 331  validation loss: 0.00308679\n",
      "epoch: 332  validation loss: 0.00308408\n",
      "epoch: 333  validation loss: 0.00308149\n",
      "epoch: 334  validation loss: 0.00307909\n",
      "epoch: 335  validation loss: 0.00307685\n",
      "epoch: 336  validation loss: 0.00307471\n",
      "epoch: 337  validation loss: 0.0030726\n",
      "epoch: 338  validation loss: 0.00307049\n",
      "epoch: 339  validation loss: 0.00306835\n",
      "epoch: 340  validation loss: 0.00306616\n",
      "epoch: 341  validation loss: 0.00306394\n",
      "epoch: 342  validation loss: 0.00306171\n",
      "epoch: 343  validation loss: 0.00305946\n",
      "epoch: 344  validation loss: 0.00305721\n",
      "epoch: 345  validation loss: 0.00305498\n",
      "epoch: 346  validation loss: 0.00305275\n",
      "epoch: 347  validation loss: 0.00305052\n",
      "epoch: 348  validation loss: 0.0030483\n",
      "epoch: 349  validation loss: 0.00304607\n",
      "epoch: 350  validation loss: 0.00304384\n",
      "epoch: 351  validation loss: 0.00304159\n",
      "epoch: 352  validation loss: 0.00303934\n",
      "epoch: 353  validation loss: 0.00303707\n",
      "epoch: 354  validation loss: 0.00303478\n",
      "epoch: 355  validation loss: 0.00303248\n",
      "epoch: 356  validation loss: 0.00303014\n",
      "epoch: 357  validation loss: 0.00302779\n",
      "epoch: 358  validation loss: 0.00302542\n",
      "epoch: 359  validation loss: 0.00302303\n",
      "epoch: 360  validation loss: 0.0030206\n",
      "epoch: 361  validation loss: 0.00301815\n",
      "epoch: 362  validation loss: 0.00301566\n",
      "epoch: 363  validation loss: 0.00301314\n",
      "epoch: 364  validation loss: 0.00301059\n",
      "epoch: 365  validation loss: 0.003008\n",
      "epoch: 366  validation loss: 0.00300537\n",
      "epoch: 367  validation loss: 0.00300269\n",
      "epoch: 368  validation loss: 0.00299999\n",
      "epoch: 369  validation loss: 0.00299722\n",
      "epoch: 370  validation loss: 0.00299443\n",
      "epoch: 371  validation loss: 0.00299157\n",
      "epoch: 372  validation loss: 0.00298867\n",
      "epoch: 373  validation loss: 0.00298571\n",
      "epoch: 374  validation loss: 0.00298272\n",
      "epoch: 375  validation loss: 0.00297967\n",
      "epoch: 376  validation loss: 0.00297656\n",
      "epoch: 377  validation loss: 0.0029734\n",
      "epoch: 378  validation loss: 0.00297019\n",
      "epoch: 379  validation loss: 0.00296693\n",
      "epoch: 380  validation loss: 0.00296361\n",
      "epoch: 381  validation loss: 0.00296023\n",
      "epoch: 382  validation loss: 0.00295681\n",
      "epoch: 383  validation loss: 0.00295334\n",
      "epoch: 384  validation loss: 0.0029498\n",
      "epoch: 385  validation loss: 0.00294621\n",
      "epoch: 386  validation loss: 0.00294258\n",
      "epoch: 387  validation loss: 0.0029389\n",
      "epoch: 388  validation loss: 0.00293516\n",
      "epoch: 389  validation loss: 0.00293137\n",
      "epoch: 390  validation loss: 0.00292755\n",
      "epoch: 391  validation loss: 0.00292368\n",
      "epoch: 392  validation loss: 0.00291976\n",
      "epoch: 393  validation loss: 0.00291582\n",
      "epoch: 394  validation loss: 0.00291183\n",
      "epoch: 395  validation loss: 0.00290782\n",
      "epoch: 396  validation loss: 0.00290376\n",
      "epoch: 397  validation loss: 0.00289968\n",
      "epoch: 398  validation loss: 0.00289557\n",
      "epoch: 399  validation loss: 0.00289145\n",
      "epoch: 400  validation loss: 0.00288729\n",
      "epoch: 401  validation loss: 0.00288311\n",
      "epoch: 402  validation loss: 0.00287894\n",
      "epoch: 403  validation loss: 0.00287474\n",
      "epoch: 404  validation loss: 0.00287052\n",
      "epoch: 405  validation loss: 0.00286632\n",
      "epoch: 406  validation loss: 0.00286209\n",
      "epoch: 407  validation loss: 0.00285788\n",
      "epoch: 408  validation loss: 0.00285367\n",
      "epoch: 409  validation loss: 0.00284946\n",
      "epoch: 410  validation loss: 0.00284526\n",
      "epoch: 411  validation loss: 0.00284108\n",
      "epoch: 412  validation loss: 0.00283691\n",
      "epoch: 413  validation loss: 0.00283277\n",
      "epoch: 414  validation loss: 0.00282865\n",
      "epoch: 415  validation loss: 0.00282454\n",
      "epoch: 416  validation loss: 0.00282047\n",
      "epoch: 417  validation loss: 0.00281644\n",
      "epoch: 418  validation loss: 0.00281246\n",
      "epoch: 419  validation loss: 0.00280851\n",
      "epoch: 420  validation loss: 0.00280461\n",
      "epoch: 421  validation loss: 0.00280076\n",
      "epoch: 422  validation loss: 0.00279697\n",
      "epoch: 423  validation loss: 0.00279326\n",
      "epoch: 424  validation loss: 0.00278961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 425  validation loss: 0.00278603\n",
      "epoch: 426  validation loss: 0.00278254\n",
      "epoch: 427  validation loss: 0.00277915\n",
      "epoch: 428  validation loss: 0.00277585\n",
      "epoch: 429  validation loss: 0.00277267\n",
      "epoch: 430  validation loss: 0.0027696\n",
      "epoch: 431  validation loss: 0.00276665\n",
      "epoch: 432  validation loss: 0.00276383\n",
      "epoch: 433  validation loss: 0.00276118\n",
      "epoch: 434  validation loss: 0.00275868\n",
      "epoch: 435  validation loss: 0.00275634\n",
      "epoch: 436  validation loss: 0.00275419\n",
      "epoch: 437  validation loss: 0.00275224\n",
      "epoch: 438  validation loss: 0.00275049\n",
      "epoch: 439  validation loss: 0.00274897\n",
      "epoch: 440  validation loss: 0.00274769\n",
      "epoch: 441  validation loss: 0.00274665\n",
      "epoch: 442  validation loss: 0.00274587\n",
      "epoch: 443  validation loss: 0.00274537\n",
      "epoch: 444  validation loss: 0.00274514\n",
      "epoch: 445  validation loss: 0.00274522\n",
      "epoch: 446  validation loss: 0.00274561\n",
      "epoch: 447  validation loss: 0.00274632\n",
      "epoch: 448  validation loss: 0.00274733\n",
      "epoch: 449  validation loss: 0.0027487\n",
      "epoch: 450  validation loss: 0.00275039\n",
      "epoch: 451  validation loss: 0.00275241\n",
      "epoch: 452  validation loss: 0.00275475\n",
      "epoch: 453  validation loss: 0.00275741\n",
      "epoch: 454  validation loss: 0.00276037\n",
      "epoch: 455  validation loss: 0.00276364\n",
      "epoch: 456  validation loss: 0.00276718\n",
      "epoch: 457  validation loss: 0.00277096\n",
      "epoch: 458  validation loss: 0.00277499\n",
      "epoch: 459  validation loss: 0.00277921\n",
      "epoch: 460  validation loss: 0.00278359\n",
      "epoch: 461  validation loss: 0.0027881\n",
      "epoch: 462  validation loss: 0.00279271\n",
      "epoch: 463  validation loss: 0.00279737\n",
      "epoch: 464  validation loss: 0.00280206\n",
      "epoch: 465  validation loss: 0.00280673\n",
      "epoch: 466  validation loss: 0.00281133\n",
      "epoch: 467  validation loss: 0.00281585\n",
      "epoch: 468  validation loss: 0.00282023\n",
      "epoch: 469  validation loss: 0.00282445\n",
      "epoch: 470  validation loss: 0.00282851\n",
      "epoch: 471  validation loss: 0.00283232\n",
      "epoch: 472  validation loss: 0.00283593\n",
      "epoch: 473  validation loss: 0.00283925\n",
      "epoch: 474  validation loss: 0.0028423\n",
      "epoch: 475  validation loss: 0.00284505\n",
      "epoch: 476  validation loss: 0.00284748\n",
      "epoch: 477  validation loss: 0.00284958\n",
      "epoch: 478  validation loss: 0.00285131\n",
      "epoch: 479  validation loss: 0.00285268\n",
      "epoch: 480  validation loss: 0.00285365\n",
      "epoch: 481  validation loss: 0.0028542\n",
      "epoch: 482  validation loss: 0.00285428\n",
      "epoch: 483  validation loss: 0.00285395\n",
      "epoch: 484  validation loss: 0.00285306\n",
      "epoch: 485  validation loss: 0.00285168\n",
      "epoch: 486  validation loss: 0.00284969\n",
      "epoch: 487  validation loss: 0.00284711\n",
      "epoch: 488  validation loss: 0.00284388\n",
      "epoch: 489  validation loss: 0.00283992\n",
      "epoch: 490  validation loss: 0.00283523\n",
      "epoch: 491  validation loss: 0.00282969\n",
      "epoch: 492  validation loss: 0.00282331\n",
      "epoch: 493  validation loss: 0.00281599\n",
      "epoch: 494  validation loss: 0.00280767\n",
      "epoch: 495  validation loss: 0.00279826\n",
      "epoch: 496  validation loss: 0.00278779\n",
      "epoch: 497  validation loss: 0.00277605\n",
      "epoch: 498  validation loss: 0.00276308\n",
      "epoch: 499  validation loss: 0.00274873\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "batch_size = 10\n",
    " \n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    " \n",
    "n_batches = N_train // batch_size\n",
    " \n",
    "log = []\n",
    "for epoch in range(epochs):\n",
    "    X_, Y_ =X_train, Y_train\n",
    " \n",
    "    for i in range(n_batches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    " \n",
    "        sess.run(train_step, feed_dict={\n",
    "            x: X_[start:end],\n",
    "            t: Y_[start:end],\n",
    "            n_batch: batch_size\n",
    "        })\n",
    " \n",
    "    # 検証データを用いた評価\n",
    "    val_loss = loss.eval(session=sess, feed_dict={\n",
    "        x: X_validation,\n",
    "        t: Y_validation,\n",
    "        n_batch: N_validation\n",
    "    })\n",
    "    \n",
    "    log.append(val_loss)\n",
    "    print('epoch:', epoch,\n",
    "          ' validation loss:', val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x116b967b8>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b851e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
